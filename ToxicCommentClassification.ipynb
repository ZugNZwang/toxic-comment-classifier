{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alex Tarasov, Eric Holguin, Gordon Zhong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a toxic comment classifier using Naive-Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import sklearn\n",
    "from heapq import nlargest\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelName = []\n",
    "toxic = 0\n",
    "labelName.append(\"Toxic\")\n",
    "severe_toxic = 1\n",
    "labelName.append(\"Severe toxic\")\n",
    "obscene = 2\n",
    "labelName.append(\"Obscene\")\n",
    "threat = 3\n",
    "labelName.append(\"Threat\")\n",
    "insult = 4\n",
    "labelName.append(\"Insult\")\n",
    "identity_hate = 5\n",
    "labelName.append(\"Identity hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the dataset obtained from Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is already split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./all/train.csv')\n",
    "test = pd.read_csv('./all/test.csv')\n",
    "test_labels = pd.read_csv('./all/test_labels.csv')\n",
    "test = pd.merge(test, test_labels, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation, duplicates and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripNonAlpha = re.compile(\"[^a-zA-Z]\")\n",
    "stripDuplicates = re.compile(r'(.)\\1+')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords = \" \".join(stopwords).replace(\"'\",\"\")\n",
    "stopwords = stripDuplicates.sub(r'\\1', stopwords).split()\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionText(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    text = text.replace(\"_\",\"\")\n",
    "    text = stripNonAlpha.sub(' ', text)\n",
    "    text = stripDuplicates.sub(r'\\1', text)\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training arrays ...\n",
      "Done building training arrays!\n",
      "Vectorizing training data ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-8f1fadef1c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconditionText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moriginaltext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoxic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginaltext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfreqTransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(\"Building training arrays ...\")\n",
    "train_X = [row.comment_text for row in train.itertuples() if row.toxic >=0]\n",
    "train_y = [None]*6\n",
    "train_y[toxic] = [row.toxic != 0 for row in train.itertuples() if row.toxic >=0]\n",
    "train_y[severe_toxic] = [row.severe_toxic != 0 for row in train.itertuples() if row.toxic >=0]\n",
    "train_y[obscene] = [row.obscene != 0 for row in train.itertuples() if row.toxic >=0]\n",
    "train_y[threat] = [row.threat != 0 for row in train.itertuples() if row.toxic >=0]\n",
    "train_y[insult] = [row.insult != 0 for row in train.itertuples() if row.toxic >=0]\n",
    "train_y[identity_hate] = [row.identity_hate != 0 for row in train.itertuples() if row.toxic >=0]\n",
    "train = None\n",
    "print(\"Done building training arrays!\")\n",
    "\n",
    "print(\"Vectorizing training data ...\")\n",
    "cv = CountVectorizer(preprocessor=conditionText)\n",
    "train_X = cv.fit_transform(train_X)\n",
    "freqTransform = TfidfTransformer(use_idf=False).fit(train_X)\n",
    "train_X = freqTransform.transform(train_X)\n",
    "print(\"Done vectorizing training data!\")\n",
    "\n",
    "print(\"Training ...\")\n",
    "gnb = []\n",
    "for i in range(6):\n",
    "    gnb.append(MultinomialNB())\n",
    "    gnb[i].fit(train_X, train_y[i])\n",
    "\n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building testing arrays ...\n",
      "Done building testing arrays!\n",
      "Vectorizing testing data ...\n",
      "Done testing data!\n"
     ]
    }
   ],
   "source": [
    "print(\"Building testing arrays ...\")\n",
    "test_X = [row.comment_text for row in test.itertuples() if row.toxic >=0]\n",
    "test_y = [None]*6\n",
    "test_y[toxic] = [row.toxic != 0 for row in test.itertuples() if row.toxic >=0]\n",
    "test_y[severe_toxic] = [row.severe_toxic != 0 for row in test.itertuples() if row.toxic >=0]\n",
    "test_y[obscene] = [row.obscene != 0 for row in test.itertuples() if row.toxic >=0]\n",
    "test_y[threat] = [row.threat != 0 for row in test.itertuples() if row.toxic >=0]\n",
    "test_y[insult] = [row.insult != 0 for row in test.itertuples() if row.toxic >=0]\n",
    "test_y[identity_hate] = [row.identity_hate != 0 for row in test.itertuples() if row.toxic >=0]\n",
    "test = None\n",
    "print(\"Done building testing arrays!\")\n",
    "\n",
    "print(\"Vectorizing testing data ...\")\n",
    "test_X = cv.transform(test_X)\n",
    "test_X = freqTransform.transform(test_X)\n",
    "print(\"Done testing data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasifying ...\n",
      "Done clasifying data!\n",
      "\n",
      "\n",
      "Toxic: \n",
      "Accuracy percent: 92.2895370283535 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      1.00      0.96     57888\n",
      "       True       0.92      0.21      0.34      6090\n",
      "\n",
      "avg / total       0.92      0.92      0.90     63978\n",
      "\n",
      "Severe toxic: \n",
      "Accuracy percent: 99.42636531307637 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      1.00     63611\n",
      "       True       0.00      0.00      0.00       367\n",
      "\n",
      "avg / total       0.99      0.99      0.99     63978\n",
      "\n",
      "Obscene: \n",
      "Accuracy percent: 94.95451561474256 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.97     60287\n",
      "       True       0.98      0.13      0.23      3691\n",
      "\n",
      "avg / total       0.95      0.95      0.93     63978\n",
      "\n",
      "Threat: \n",
      "Accuracy percent: 99.67019913095126 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       1.00      1.00      1.00     63767\n",
      "       True       0.00      0.00      0.00       211\n",
      "\n",
      "avg / total       0.99      1.00      1.00     63978\n",
      "\n",
      "Insult: \n",
      "Accuracy percent: 94.93263309262558 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.95      1.00      0.97     60551\n",
      "       True       0.92      0.06      0.11      3427\n",
      "\n",
      "avg / total       0.95      0.95      0.93     63978\n",
      "\n",
      "Identity hate: \n",
      "Accuracy percent: 98.88711744662227 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      1.00      0.99     63266\n",
      "       True       0.00      0.00      0.00       712\n",
      "\n",
      "avg / total       0.98      0.99      0.98     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Clasifying ...\")\n",
    "test_z = []\n",
    "for g in gnb:\n",
    "    test_z.append(g.predict(test_X))\n",
    "print(\"Done clasifying data!\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for z, y, l in zip(test_z, test_y, labelName):\n",
    "    print(l+\": \")\n",
    "    print(\"Accuracy percent:\", sklearn.metrics.accuracy_score(y, z)*100,\"\\n\")\n",
    "    print(sklearn.metrics.classification_report(y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
